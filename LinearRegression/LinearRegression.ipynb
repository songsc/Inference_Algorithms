{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.58  5.46  6.62 -3.42 -1.5 ]\n",
      " [-2.95  2.01  9.35  6.37 -0.17]\n",
      " [-6.83  5.36  2.25 -5.79  0.51]\n",
      " [ 4.26 -1.25 -5.04 -3.28 -4.44]\n",
      " [-6.16  2.43 -3.72  2.8   6.9 ]\n",
      " [ 9.18  3.18 -9.14  1.93 -9.22]\n",
      " [-9.01 -8.6   7.17 -7.66 -6.05]\n",
      " [ 8.66 -1.71  5.2   1.02  2.98]\n",
      " [ 2.28 -2.41  7.9   3.49  0.08]\n",
      " [ 1.73 -8.08 -0.38 -9.83  5.44]\n",
      " [ 7.12 -0.03  0.38 -0.94  2.38]\n",
      " [ 4.7   2.47 -9.1  -3.69 -8.07]\n",
      " [-9.48  4.67 -0.9   2.38 -1.22]\n",
      " [-4.64  5.87 -1.59 -5.65  9.68]\n",
      " [-5.33 -2.06  0.72 -8.39 -3.8 ]\n",
      " [-9.07 -9.16 -7.58 -0.25  0.89]\n",
      " [-0.26  3.8   1.6   4.35  3.56]\n",
      " [ 6.69  1.88 -2.81  1.36  2.37]\n",
      " [-2.4   7.95  8.45  6.07  1.71]\n",
      " [-8.84  9.36 -5.21  0.19  2.11]\n",
      " [ 4.55  4.23 -0.21  4.97 -8.62]\n",
      " [ 5.38  7.39  3.47 -6.46 -5.73]\n",
      " [-7.49  8.69 -7.21 -7.93  0.89]\n",
      " [-9.36  0.94  0.51 -7.64  2.65]\n",
      " [ 8.26  8.95  9.86 -1.85  5.29]\n",
      " [ 5.25 -8.67  7.38  5.64  9.21]\n",
      " [-9.98  9.46  1.24 -6.8  -8.53]\n",
      " [ 5.07 -8.52  3.82 -8.17  6.85]\n",
      " [ 2.4   0.95  3.59  6.89 -7.55]\n",
      " [ 6.18 -0.08 -1.21 -8.06 -3.01]\n",
      " [ 6.99  9.64  6.96 -7.17 -8.25]\n",
      " [-1.93  3.86  3.83  4.19  2.49]\n",
      " [ 9.03 -6.27  7.14 -1.94  9.76]\n",
      " [ 0.42 -8.09  1.54 -3.6  -9.67]\n",
      " [ 1.74 -4.34 -6.21 -9.97  6.73]\n",
      " [ 0.64  6.51  8.03 -4.92  3.89]\n",
      " [-1.39 -5.79  6.56  4.28 -2.06]\n",
      " [ 2.33  4.39  6.96  8.21 -6.85]\n",
      " [-9.48 -1.78  3.22  5.59 -0.37]\n",
      " [ 9.68 -5.57  9.36  3.8   1.51]\n",
      " [ 7.89 -0.89  1.86 -6.9   6.95]\n",
      " [-1.43 -0.93 -9.53  2.05 -8.56]\n",
      " [ 7.4  -1.99 -9.56  1.01  1.49]\n",
      " [ 7.32 -5.65  1.98 -4.49 -8.32]\n",
      " [ 2.47  5.26  4.71  4.37 -6.71]\n",
      " [-2.84  9.68 -7.79 -5.58 -3.23]\n",
      " [ 1.11 -9.54 -0.03 -3.4  -4.  ]\n",
      " [ 0.28  4.42 -6.83  0.77  8.24]\n",
      " [-4.93  5.77 -2.35 -7.86  9.78]\n",
      " [ 6.17  3.17 -8.77  5.58  7.17]\n",
      " [ 3.28  7.19 -2.62  4.89  6.28]\n",
      " [-0.19 -2.63 -6.72  8.37  5.63]\n",
      " [ 9.78 -3.4  -7.45 -7.15  7.64]\n",
      " [-9.27  3.21  0.53  2.64  9.28]\n",
      " [-4.5   6.62  4.12 -0.29  1.61]\n",
      " [-7.17  4.36  0.1   7.57 -0.39]\n",
      " [-2.32  5.35 -4.96 -8.81  6.75]\n",
      " [-4.85  5.08  0.2  -7.04  8.03]\n",
      " [-1.8   7.58 -4.43  5.47  6.94]\n",
      " [-6.85 -2.84 -4.24  5.08  6.63]\n",
      " [-0.89  1.86 -5.31 -7.19 -7.1 ]\n",
      " [-9.02 -2.72  7.38  8.91  7.26]\n",
      " [-5.02  7.53 -2.68  9.2  -9.95]\n",
      " [-4.22  5.36 -9.94  7.21  3.84]\n",
      " [-0.02  0.37  7.75  7.44 -1.11]\n",
      " [-9.06 -6.42 -2.85 -3.79  0.18]\n",
      " [ 9.32  5.37 -7.48 -0.04  2.34]\n",
      " [ 0.53 -0.09 -7.75  8.96  6.28]\n",
      " [-1.78 -3.   -6.25  7.19 -8.  ]\n",
      " [ 2.67  6.48 -4.64 -8.58  0.9 ]]\n",
      "[[ -6.16e+00   2.59e+00  -6.13e+00   5.20e+00  -8.84e+00]\n",
      " [ -8.09e+00   5.99e+00   2.28e-02   2.03e+00   2.51e+00]\n",
      " [ -7.75e+00   8.90e+00  -5.21e+00   3.28e+00  -5.18e+00]\n",
      " [  6.15e-01  -6.94e+00   3.95e+00   3.67e+00   1.74e+00]\n",
      " [ -5.65e-01  -3.24e+00  -4.09e+00  -1.85e+00   7.47e+00]\n",
      " [ -8.91e+00  -3.65e+00  -7.08e-03  -3.31e-01   8.63e+00]\n",
      " [ -3.65e+00   9.15e+00  -6.86e+00   9.59e+00  -1.46e+00]\n",
      " [  2.18e+00  -3.91e+00   8.02e+00   2.87e+00   3.86e+00]\n",
      " [  3.70e+00   9.37e+00   9.62e+00  -9.66e+00   1.65e+00]\n",
      " [  9.45e+00  -1.20e+00   3.61e+00   8.10e+00   1.14e+00]\n",
      " [ -7.43e+00   8.30e+00  -4.58e+00  -7.87e+00  -4.53e+00]\n",
      " [  1.03e-01   3.90e+00  -9.17e+00   3.23e+00  -7.10e+00]\n",
      " [ -1.74e+00  -1.43e+00  -1.30e+00   6.95e+00  -1.10e+00]\n",
      " [  8.02e+00  -7.57e+00  -8.44e+00   2.84e+00   8.42e+00]\n",
      " [ -5.89e+00  -8.84e+00  -3.26e-02  -9.05e+00  -1.40e+00]\n",
      " [ -8.78e+00  -4.02e+00   7.00e+00   3.33e+00  -2.03e+00]\n",
      " [  8.58e+00   3.71e+00  -3.75e+00   4.02e+00  -2.98e+00]\n",
      " [ -9.35e+00  -2.41e+00  -2.73e-01   6.73e+00   6.43e+00]\n",
      " [ -3.98e+00  -2.87e+00   2.49e+00  -5.81e+00  -9.74e-01]\n",
      " [ -1.36e+00  -6.69e+00  -7.91e+00  -1.02e+00   7.45e+00]\n",
      " [ -2.99e+00   7.82e-02   1.41e+00   3.44e+00  -5.32e+00]\n",
      " [ -1.07e+00   2.95e+00   1.28e-01  -5.43e+00  -4.06e+00]\n",
      " [ -4.91e+00  -9.42e+00   9.56e+00  -8.50e+00   7.50e+00]\n",
      " [ -7.38e+00   1.74e+00   6.27e+00  -7.19e+00   9.40e+00]\n",
      " [ -5.45e+00   5.29e+00  -5.36e+00   1.66e-01   2.33e+00]\n",
      " [ -1.03e+00   8.35e+00   4.87e+00   7.29e+00  -2.93e-01]\n",
      " [  3.62e+00  -1.53e+00  -3.79e+00   6.67e+00  -6.82e+00]\n",
      " [  5.89e+00   9.29e+00  -2.34e+00  -4.63e+00  -9.68e+00]\n",
      " [ -4.96e+00   3.43e+00   4.80e+00   5.32e+00   9.59e+00]\n",
      " [ -6.26e+00   6.69e+00  -8.36e+00  -5.97e+00   2.86e-01]]\n",
      "Iter:   0, MSE-train: 1809.63, weights: [[ 0.38  0.96  2.02  2.83  3.31]], bias: 0.06\n",
      "Iter:   1, MSE-train: 207.94, weights: [[ 0.69  1.47  2.66  3.66  4.42]], bias: 0.07\n",
      "Iter:   2, MSE-train: 28.29, weights: [[ 0.85  1.72  2.88  3.9   4.78]], bias: 0.07\n",
      "Iter:   3, MSE-train: 5.16, weights: [[ 0.93  1.85  2.95  3.98  4.91]], bias: 0.05\n",
      "Iter:   4, MSE-train: 1.72, weights: [[ 0.97  1.91  2.98  4.    4.95]], bias: 0.04\n",
      "Iter:   5, MSE-train: 1.12, weights: [[ 0.98  1.93  2.99  4.01  4.97]], bias: 0.02\n",
      "Iter:   6, MSE-train: 0.99, weights: [[ 0.99  1.95  3.    4.01  4.98]], bias: 0.00\n",
      "Iter:   7, MSE-train: 0.93, weights: [[ 0.99  1.95  3.    4.01  4.98]], bias: -0.02\n",
      "Iter:   8, MSE-train: 0.90, weights: [[ 1.    1.96  3.    4.01  4.98]], bias: -0.04\n",
      "Iter:   9, MSE-train: 0.86, weights: [[ 1.    1.96  3.    4.01  4.98]], bias: -0.05\n",
      "Iter:  50, MSE-train: 0.19, weights: [[ 1.    1.98  3.    4.    4.99]], bias: -0.56\n",
      "Iter: 100, MSE-train: 0.03, weights: [[ 1.    1.99  3.    4.    5.  ]], bias: -0.83\n",
      "Iter: 150, MSE-train: 0.00, weights: [[ 1.  2.  3.  4.  5.]], bias: -0.93\n",
      "Iter: 200, MSE-train: 0.00, weights: [[ 1.  2.  3.  4.  5.]], bias: -0.97\n",
      "Final testing MSE: 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "    \n",
    "def linReg(data_file, target_file):\n",
    "    \n",
    "    # W for weights, b for biases, X for inputs, Y_T for \n",
    "    W = tf.Variable(tf.zeros([5, 1]), name='Weights')\n",
    "    b = tf.Variable(0.0, name='Biases')\n",
    "    X = tf.placeholder(tf.float32, [None, 5], name='Input_X')\n",
    "    Y_T = tf.placeholder(tf.float32, [None, 1], name='Target_Y')\n",
    "\n",
    "    \n",
    "    # Y_P = [X] x [W] + [b]\n",
    "    Y_P = tf.matmul(X, W) + b\n",
    "    # MSE = avg((Y_P -Y_T)^2)\n",
    "    MSE = tf.reduce_mean(tf.reduce_mean(tf.square(Y_P - Y_T), reduction_indices=1, name='Squared_Error'), \n",
    "                         name='Mean_Squared_Error')\n",
    "\n",
    "    # Use Gradient Descent method to minimize MSE\n",
    "    # Learning rate can be varied\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss = MSE)\n",
    "    \n",
    "    # Load data from files\n",
    "    inputData = np.load(data_file)\n",
    "    target = np.load(target_file)    \n",
    "    trainData = inputData[:,0:70].T\n",
    "    testData = inputData[:,70:].T\n",
    "    print(trainData)\n",
    "    print(testData)\n",
    "\n",
    "    trainTarget = np.expand_dims(target[0:70], 1)\n",
    "    testTarget = np.expand_dims(target[70:],1)\n",
    "    \n",
    "    # Initialization\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    initialW = sess.run(W)  \n",
    "    initialb = sess.run(b)\n",
    "\n",
    "    # Training model\n",
    "    wList = []\n",
    "    for step in range(0,201):\n",
    "        _, err, currentW, currentb, yhat = sess.run([train, MSE, W, b, Y_P], feed_dict={X: trainData, Y_T: trainTarget})\n",
    "        wList.append(currentW)\n",
    "        if not (step % 50) or step < 10:        \n",
    "            print(\"Iter: %3d, MSE-train: %4.2f, weights: %s, bias: %.2f\"%(step, err, currentW.T, currentb))\n",
    "\n",
    "    # Testing model\n",
    "    errTest = sess.run(MSE, feed_dict={X: testData, Y_T: testTarget})\n",
    "    print(\"Final testing MSE: %.2f\"%(errTest))      \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.set_printoptions(precision=2)\n",
    "    linReg('./x.npy', './t.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
